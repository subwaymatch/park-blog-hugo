{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6e4426-8fbd-4434-a2cf-32e7f6116cc3",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using spaCy and DistilBERT\n",
    "\n",
    "Natural language processing (NLP) aims to give computers the ability to understand, process, and even generate human language. This notebook introduces the common preprocessing steps and demonstrates how to use a widely used transformer model (`distilbert-base-uncased-finetuned-sst-2-english`) to perfrom a sentiment analysis. üòÄüò¶üôÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31b7a34-007c-4e89-8916-a07406598896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d48c8d9-b347-4596-afe2-acbe54df942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8fe7ba-291c-4abc-b95a-f80f4d6bba1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üóÉÔ∏è Load data\n",
    "\n",
    "This exercise uses a small dataset that contains reviews of two apartments at Indiana University Bloomington.\n",
    "\n",
    "1. [State On Campus Bloomington](https://stateoncampus.com/bloomington/)\n",
    "2. [The Standard at Bloomington](https://www.thestandardbloomington.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090f5a2e-2e23-4da0-8d7d-401d892e2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = pd.read_csv(\n",
    "    'https://github.com/bdi475/datasets/raw/main/campustowns-leasing-company-reviews/businesses-sample.csv'\n",
    ")\n",
    "df_r = pd.read_csv(\n",
    "    'https://github.com/bdi475/datasets/raw/main/campustowns-leasing-company-reviews/reviews-sample.csv',\n",
    "    parse_dates = ['review_datetime_utc', 'owner_answer_timestamp_datetime_utc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9bf5636-8f27-43c7-862c-3e9f936170c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campus</th>\n",
       "      <th>place_id</th>\n",
       "      <th>name</th>\n",
       "      <th>site</th>\n",
       "      <th>category</th>\n",
       "      <th>borough</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indiana University Bloomington</td>\n",
       "      <td>ChIJY1yB5NJmbIgRZn7E2oF5gVQ</td>\n",
       "      <td>State On Campus Bloomington</td>\n",
       "      <td>https://stateoncampus.com/bloomington/?utm_sou...</td>\n",
       "      <td>Apartment complex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2036 N Walnut St</td>\n",
       "      <td>Bloomington</td>\n",
       "      <td>47404</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>39.184846</td>\n",
       "      <td>-86.532875</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indiana University Bloomington</td>\n",
       "      <td>ChIJPb8SbdpnbIgR82bkOLSKtZM</td>\n",
       "      <td>The Standard at Bloomington</td>\n",
       "      <td>https://www.thestandardbloomington.com/?utm_so...</td>\n",
       "      <td>Student housing center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250 E 14th St</td>\n",
       "      <td>Bloomington</td>\n",
       "      <td>47408</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>39.175974</td>\n",
       "      <td>-86.531609</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           campus                     place_id  \\\n",
       "0  Indiana University Bloomington  ChIJY1yB5NJmbIgRZn7E2oF5gVQ   \n",
       "1  Indiana University Bloomington  ChIJPb8SbdpnbIgR82bkOLSKtZM   \n",
       "\n",
       "                          name  \\\n",
       "0  State On Campus Bloomington   \n",
       "1  The Standard at Bloomington   \n",
       "\n",
       "                                                site                category  \\\n",
       "0  https://stateoncampus.com/bloomington/?utm_sou...       Apartment complex   \n",
       "1  https://www.thestandardbloomington.com/?utm_so...  Student housing center   \n",
       "\n",
       "   borough            street         city  postal_code    state   latitude  \\\n",
       "0      NaN  2036 N Walnut St  Bloomington        47404  Indiana  39.184846   \n",
       "1      NaN     250 E 14th St  Bloomington        47408  Indiana  39.175974   \n",
       "\n",
       "   longitude  verified  \n",
       "0 -86.532875      True  \n",
       "1 -86.531609      True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# businesses\n",
    "display(df_b.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49a5620-4101-4c63-b37e-3d75b150a864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_img_url</th>\n",
       "      <th>review_datetime_utc</th>\n",
       "      <th>owner_answer</th>\n",
       "      <th>owner_answer_timestamp_datetime_utc</th>\n",
       "      <th>review_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChIJY1yB5NJmbIgRZn7E2oF5gVQ</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE</td>\n",
       "      <td>109839330111495228413</td>\n",
       "      <td>Aziz Bohra</td>\n",
       "      <td>This place has my heart! Spacious rooms, quali...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://lh5.googleusercontent.com/p/AF1QipM0Jm...</td>\n",
       "      <td>2023-04-01 03:19:15+00:00</td>\n",
       "      <td>Thanks for your feedback.  We are grateful tha...</td>\n",
       "      <td>2022-11-01 18:54:45+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChIJY1yB5NJmbIgRZn7E2oF5gVQ</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNaOC15NkhBEAE</td>\n",
       "      <td>102607480175477014087</td>\n",
       "      <td>Nessa Bacher</td>\n",
       "      <td>I‚Äôll start with the positives of living at Sta...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-25 00:17:21+00:00</td>\n",
       "      <td>We are so pleased to hear that you enjoy livin...</td>\n",
       "      <td>2023-09-18 14:20:59+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      place_id                            review_id  \\\n",
       "0  ChIJY1yB5NJmbIgRZn7E2oF5gVQ  ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE   \n",
       "1  ChIJY1yB5NJmbIgRZn7E2oF5gVQ  ChZDSUhNMG9nS0VJQ0FnSUNaOC15NkhBEAE   \n",
       "\n",
       "               author_id  author_title  \\\n",
       "0  109839330111495228413    Aziz Bohra   \n",
       "1  102607480175477014087  Nessa Bacher   \n",
       "\n",
       "                                         review_text  review_rating  \\\n",
       "0  This place has my heart! Spacious rooms, quali...              5   \n",
       "1  I‚Äôll start with the positives of living at Sta...              4   \n",
       "\n",
       "                                      review_img_url  \\\n",
       "0  https://lh5.googleusercontent.com/p/AF1QipM0Jm...   \n",
       "1                                                NaN   \n",
       "\n",
       "        review_datetime_utc  \\\n",
       "0 2023-04-01 03:19:15+00:00   \n",
       "1 2023-09-25 00:17:21+00:00   \n",
       "\n",
       "                                        owner_answer  \\\n",
       "0  Thanks for your feedback.  We are grateful tha...   \n",
       "1  We are so pleased to hear that you enjoy livin...   \n",
       "\n",
       "  owner_answer_timestamp_datetime_utc  review_likes  \n",
       "0           2022-11-01 18:54:45+00:00             0  \n",
       "1           2023-09-18 14:20:59+00:00             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reviews table\n",
    "display(df_r.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56af66fe-af3c-4d56-a58b-0f1924daf54a",
   "metadata": {},
   "source": [
    "Print the `info()` of the two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31288b36-9bee-4290-8e4b-5343e590a28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   campus       2 non-null      object \n",
      " 1   place_id     2 non-null      object \n",
      " 2   name         2 non-null      object \n",
      " 3   site         2 non-null      object \n",
      " 4   category     2 non-null      object \n",
      " 5   borough      0 non-null      float64\n",
      " 6   street       2 non-null      object \n",
      " 7   city         2 non-null      object \n",
      " 8   postal_code  2 non-null      int64  \n",
      " 9   state        2 non-null      object \n",
      " 10  latitude     2 non-null      float64\n",
      " 11  longitude    2 non-null      float64\n",
      " 12  verified     2 non-null      bool   \n",
      "dtypes: bool(1), float64(3), int64(1), object(8)\n",
      "memory usage: 322.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_b.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d66e8cd4-f77f-4884-a2c6-984eea97f7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312 entries, 0 to 311\n",
      "Data columns (total 11 columns):\n",
      " #   Column                               Non-Null Count  Dtype              \n",
      "---  ------                               --------------  -----              \n",
      " 0   place_id                             312 non-null    object             \n",
      " 1   review_id                            312 non-null    object             \n",
      " 2   author_id                            312 non-null    object             \n",
      " 3   author_title                         312 non-null    object             \n",
      " 4   review_text                          236 non-null    object             \n",
      " 5   review_rating                        312 non-null    int64              \n",
      " 6   review_img_url                       6 non-null      object             \n",
      " 7   review_datetime_utc                  312 non-null    datetime64[ns, UTC]\n",
      " 8   owner_answer                         245 non-null    object             \n",
      " 9   owner_answer_timestamp_datetime_utc  245 non-null    datetime64[ns, UTC]\n",
      " 10  review_likes                         312 non-null    int64              \n",
      "dtypes: datetime64[ns, UTC](2), int64(2), object(7)\n",
      "memory usage: 26.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_r.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0342f66-2d12-492f-84e2-ee8afcb83839",
   "metadata": {},
   "source": [
    "The dataset has 312 reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58317ee-85e1-4554-9987-50058c637dc4",
   "metadata": {},
   "source": [
    "## ü™ì Preprocess review text using spaCy\n",
    "\n",
    "[spaCy](https://spacy.io/) is a powerful, open-source library for advanced Natural Language Processing (NLP) in Python and Cython. Designed specifically for production use, spaCy helps developers build applications that process and understand large volumes of text data efficiently.\n",
    "\n",
    "spaCy is particularly useful for:\n",
    "\n",
    "- Information extraction\n",
    "- Natural language understanding systems\n",
    "- Text pre-processing for deep learning\n",
    "- Building chatbots and language-based applications\n",
    "- Analyzing large volumes of unstructured text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b24cef9-2a97-4220-8b3b-eb7efbd1b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f56d96-e3e6-433f-b8db-e874507fe3a2",
   "metadata": {},
   "source": [
    "### Trained pipelines\n",
    "\n",
    "Trained pipelines are models that enable spaCy to predict linguistic attributes in context\n",
    "\n",
    "- Part-of-speech tags\n",
    "- Syntactic dependencies\n",
    "- Named entities\n",
    "\n",
    "`'en_core_web_sm'` is a English pipeline optimized for CPU.\n",
    "\n",
    "Components: \n",
    "\n",
    "- tok2vec\n",
    "- taggerparser\n",
    "- senter\n",
    "- ner\n",
    "- attribute_ruler\n",
    "- lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b38c9d-3a05-4950-b891-ca5cf5c6d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33afd8dd-c841-4d50-96b5-30dada444a34",
   "metadata": {},
   "source": [
    "`spacy.load()` returns a `Language` object containing all components and data needed to process text. Calling the returned object on a string of text will return a processed `Doc`.\n",
    "\n",
    "Source: [https://spacy.io/usage/spacy-101](https://spacy.io/usage/spacy-101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5361992-6f60-4a41-af12-b2a55956f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "text: I\n",
      "lemma: I\n",
      "pos: PRON\n",
      "explain: pronoun\n",
      "is_stop: True\n",
      "------------------\n",
      "text: love\n",
      "lemma: love\n",
      "pos: VERB\n",
      "explain: verb\n",
      "is_stop: False\n",
      "------------------\n",
      "text: this\n",
      "lemma: this\n",
      "pos: DET\n",
      "explain: determiner\n",
      "is_stop: True\n",
      "------------------\n",
      "text: apartment\n",
      "lemma: apartment\n",
      "pos: NOUN\n",
      "explain: noun\n",
      "is_stop: False\n"
     ]
    }
   ],
   "source": [
    "text = 'I love this apartment'\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print('------------------')\n",
    "    print(f'text: {token.text}')\n",
    "    print(f'lemma: {token.lemma_}')\n",
    "    print(f'pos: {token.pos_}') # pos_ stands for part-of-speech\n",
    "    print(f'explain: {spacy.explain(token.pos_)}')\n",
    "    print(f'is_stop: {token.is_stop}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09e847-ee8e-47c5-be77-5412459f4572",
   "metadata": {},
   "source": [
    "Visualize the dependency parse using `displacy.render()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6731b4c-c2bc-4d75-a97e-2e3a10813297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"7f17381174d042f6bc91b5bfd7e30151-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">love</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">this</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">apartment</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f17381174d042f6bc91b5bfd7e30151-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f17381174d042f6bc91b5bfd7e30151-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f17381174d042f6bc91b5bfd7e30151-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f17381174d042f6bc91b5bfd7e30151-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7f17381174d042f6bc91b5bfd7e30151-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7f17381174d042f6bc91b5bfd7e30151-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c02ab0-6e24-4cbb-8c26-e840cf5e37e8",
   "metadata": {},
   "source": [
    "### Tokenization and lemmatization\n",
    "\n",
    "Tokenization takes a piece of text and breaks it down into meaningful units called \"tokens.\" These tokens can be individual words, punctuation marks, numbers, or even phrases depending on the task and chosen method.\n",
    "\n",
    "Lemmatization goes a step further, focusing on the \"base form\" or \"dictionary form\" of words. It groups together different grammatical variations of the same word (like \"playing,\" \"plays,\" \"played\") and reduces them to their core meaning (\"play\"). This helps capture the true meaning of the text regardless of how they are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9016dda5-a088-4f17-95ae-19390110b236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>explain</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apartment</td>\n",
       "      <td>apartment</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text      lemma   pos     explain  is_stop\n",
       "0          I          I  PRON     pronoun     True\n",
       "1       love       love  VERB        verb    False\n",
       "2       this       this   DET  determiner     True\n",
       "3  apartment  apartment  NOUN        noun    False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"text\", \"lemma\", \"pos\", \"explain\", \"is_stop\"]\n",
    "rows = []\n",
    "\n",
    "for t in doc:\n",
    "    row = [t.text, t.lemma_, t.pos_, spacy.explain(t.pos_), t.is_stop]\n",
    "    rows.append(row)\n",
    "\n",
    "df_tokens = pd.DataFrame(rows, columns=cols)\n",
    "df_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3880ee0c-1135-4778-970a-ebb2f8a0c9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>explain</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE</td>\n",
       "      <td>This</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE</td>\n",
       "      <td>place</td>\n",
       "      <td>place</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE</td>\n",
       "      <td>has</td>\n",
       "      <td>have</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE</td>\n",
       "      <td>my</td>\n",
       "      <td>my</td>\n",
       "      <td>PRON</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE</td>\n",
       "      <td>heart</td>\n",
       "      <td>heart</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18255</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNSdUpEV2FREAE</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18256</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNSeUp1dUVBEAE</td>\n",
       "      <td>Hooray</td>\n",
       "      <td>Hooray</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>proper noun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18257</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNSeUp1dUVBEAE</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18258</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUR4aDZQckl3EAE</td>\n",
       "      <td>wowie</td>\n",
       "      <td>wowie</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18259</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUR4aDZQckl3EAE</td>\n",
       "      <td>zowa</td>\n",
       "      <td>zowa</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>proper noun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18260 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 review_id    text   lemma    pos  \\\n",
       "0      ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE    This    this    DET   \n",
       "1      ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE   place   place   NOUN   \n",
       "2      ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE     has    have   VERB   \n",
       "3      ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE      my      my   PRON   \n",
       "4      ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE   heart   heart   NOUN   \n",
       "...                                    ...     ...     ...    ...   \n",
       "18255  ChZDSUhNMG9nS0VJQ0FnSUNSdUpEV2FREAE       !       !  PUNCT   \n",
       "18256  ChZDSUhNMG9nS0VJQ0FnSUNSeUp1dUVBEAE  Hooray  Hooray  PROPN   \n",
       "18257  ChZDSUhNMG9nS0VJQ0FnSUNSeUp1dUVBEAE       !       !  PUNCT   \n",
       "18258  ChZDSUhNMG9nS0VJQ0FnSUR4aDZQckl3EAE   wowie   wowie   VERB   \n",
       "18259  ChZDSUhNMG9nS0VJQ0FnSUR4aDZQckl3EAE    zowa    zowa  PROPN   \n",
       "\n",
       "           explain  is_stop  \n",
       "0       determiner     True  \n",
       "1             noun    False  \n",
       "2             verb     True  \n",
       "3          pronoun     True  \n",
       "4             noun    False  \n",
       "...            ...      ...  \n",
       "18255  punctuation    False  \n",
       "18256  proper noun    False  \n",
       "18257  punctuation    False  \n",
       "18258         verb    False  \n",
       "18259  proper noun    False  \n",
       "\n",
       "[18260 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"review_id\", \"text\", \"lemma\", \"pos\", \"explain\", \"is_stop\"]\n",
    "rows = []\n",
    "\n",
    "for index, row in df_r[df_r['review_text'].notna()].iterrows():\n",
    "    doc = nlp(row['review_text'])\n",
    "    for t in doc:\n",
    "        new_row = [row['review_id'], t.text, t.lemma_, t.pos_, spacy.explain(t.pos_), t.is_stop]\n",
    "        rows.append(new_row)\n",
    "\n",
    "df_tokens = pd.DataFrame(rows, columns=cols)\n",
    "df_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48b4a0-ff3f-40d8-897e-c21d55127217",
   "metadata": {},
   "source": [
    "### Remove stop words\n",
    "\n",
    "Stop words, as you might guess from the name, are a set of commonly used words in a language that are often filtered out before processing text in Natural Language Processing (NLP) tasks. These words, like \"the,\" \"a,\" \"is,\" \"and,\" \"on,\" etc., are considered to carry little independent meaning and contribute minimally to the overall understanding of the text.\n",
    "\n",
    "We remove the stop words here for two reasons:\n",
    "\n",
    "1. Reduce noise: By removing commonly used words, we focus on the content-rich keywords that convey the core meaning of the text.\n",
    "2. Improve efficiency: Removing stop words reduces the overall size of the data, making NLP tasks faster and less computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36797eb5-ef67-4aa5-8c9d-1750f8170eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>explain</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE</td>\n",
       "      <td>place</td>\n",
       "      <td>place</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE</td>\n",
       "      <td>heart</td>\n",
       "      <td>heart</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE</td>\n",
       "      <td>Spacious</td>\n",
       "      <td>spacious</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE</td>\n",
       "      <td>rooms</td>\n",
       "      <td>room</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE</td>\n",
       "      <td>quality</td>\n",
       "      <td>quality</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18252</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNSdUpEV2FREAE</td>\n",
       "      <td>staff</td>\n",
       "      <td>staff</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18254</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNSdUpEV2FREAE</td>\n",
       "      <td>awesome</td>\n",
       "      <td>awesome</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18256</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNSeUp1dUVBEAE</td>\n",
       "      <td>Hooray</td>\n",
       "      <td>Hooray</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>proper noun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18258</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUR4aDZQckl3EAE</td>\n",
       "      <td>wowie</td>\n",
       "      <td>wowie</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18259</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUR4aDZQckl3EAE</td>\n",
       "      <td>zowa</td>\n",
       "      <td>zowa</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>proper noun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5948 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 review_id      text     lemma    pos  \\\n",
       "1      ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE     place     place   NOUN   \n",
       "4      ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE     heart     heart   NOUN   \n",
       "6      ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE  Spacious  spacious    ADJ   \n",
       "7      ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE     rooms      room   NOUN   \n",
       "9      ChZDSUhNMG9nS0VJQ0FnSUMtbE1XaWR3EAE   quality   quality   NOUN   \n",
       "...                                    ...       ...       ...    ...   \n",
       "18252  ChZDSUhNMG9nS0VJQ0FnSUNSdUpEV2FREAE     staff     staff   NOUN   \n",
       "18254  ChZDSUhNMG9nS0VJQ0FnSUNSdUpEV2FREAE   awesome   awesome    ADJ   \n",
       "18256  ChZDSUhNMG9nS0VJQ0FnSUNSeUp1dUVBEAE    Hooray    Hooray  PROPN   \n",
       "18258  ChZDSUhNMG9nS0VJQ0FnSUR4aDZQckl3EAE     wowie     wowie   VERB   \n",
       "18259  ChZDSUhNMG9nS0VJQ0FnSUR4aDZQckl3EAE      zowa      zowa  PROPN   \n",
       "\n",
       "           explain  is_stop  \n",
       "1             noun    False  \n",
       "4             noun    False  \n",
       "6        adjective    False  \n",
       "7             noun    False  \n",
       "9             noun    False  \n",
       "...            ...      ...  \n",
       "18252         noun    False  \n",
       "18254    adjective    False  \n",
       "18256  proper noun    False  \n",
       "18258         verb    False  \n",
       "18259  proper noun    False  \n",
       "\n",
       "[5948 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only filter non stop words\n",
    "df_tokens_filtered = df_tokens[~df_tokens['is_stop']]\n",
    "\n",
    "# remove words shorter than 4 characters long\n",
    "df_tokens_filtered = df_tokens_filtered[df_tokens_filtered['lemma'].str.len() >= 4]\n",
    "\n",
    "df_tokens_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874f747-cacf-4a8c-94fd-931d9af29af8",
   "metadata": {},
   "source": [
    "Display value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc897da7-e2ef-4ca4-ad1f-28e2ed43c80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lemma\n",
       "apartment     125\n",
       "live          119\n",
       "place          98\n",
       "staff          73\n",
       "helpful        62\n",
       "             ... \n",
       "respectful      1\n",
       "exit            1\n",
       "hook            1\n",
       "climbing        1\n",
       "rock            1\n",
       "Name: count, Length: 1470, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens_filtered['lemma'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9784b5c6-839a-443a-b9af-e8c28a6c92e6",
   "metadata": {},
   "source": [
    "## üß™ Sentiment analysis using DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e435b664-d1c3-4892-8fd1-68d2d160c586",
   "metadata": {},
   "source": [
    "[DistilBERT](https://huggingface.co/docs/transformers/en/model_doc/distilbert) is a lightweight, efficient version of the BERT (Bidirectional Encoder Representations from Transformers) language model, designed for faster training and inference while maintaining competitive performance in natural language processing (NLP) tasks. Developed by HuggingFace, DistilBERT is a distilled version of BERT that retains 97% of its language understanding capabilities while being 40% smaller and 60% faster.\n",
    "\n",
    "The transformer architecture is like BERT's brain. \n",
    "\n",
    "From [Hugging Face's Documentation](https://huggingface.co/docs/transformers/main/en/index):\n",
    "\n",
    "> Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as:\n",
    "\n",
    "> üìù **Natural Language Processing**: text classification, named entity recognition, question answering, language modeling, summarization, translation, multiple choice, and text generation.\n",
    "\n",
    "\n",
    "### What is BERT?\n",
    "\n",
    "Here's a simple explanation of BERT and the transformer architecture for a five-year-old (with the help of [perplexity.ai](https://perplexity.ai/)):\n",
    "\n",
    "Imagine you're playing with a super-smart toy robot that can read and understand stories. This robot is called BERT. When BERT reads a story, it doesn't just look at one word at a time like some other robots. Instead, it looks at all the words in a sentence together, kind of like how you look at a whole picture instead of just one tiny part.\n",
    "\n",
    "1. Think of transformers as a **team of helper robots** working together to understand language.\n",
    "2. These helper robots have special **\"attention\"** powers. When they read a sentence, they can focus on different words at the same time, just like how you can look at different toys in your room all at once.\n",
    "3. The helpers **talk to each other** and share what they've learned about each word. This helps them understand the whole sentence better, like how you understand a story better when you and your friends talk about it together.\n",
    "4. These helper robots can learn from lots and lots of stories, so they become very good at understanding language, just like how you get better at reading the more books you read.\n",
    "5. After they've learned from many stories, they can help with all sorts of language tasks, like answering questions or figuring out if someone is happy or sad in a story.\n",
    "\n",
    "So, BERT is like a super-smart reading buddy that uses these helper robots (transformers) to understand language in a way that's similar to how you understand stories ‚Äì by looking at everything together and sharing information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49f5b4-0d7b-448d-a038-a5703af04108",
   "metadata": {},
   "source": [
    "### Transfomers\n",
    "\n",
    "Transformers, provided [Hugging Face](https://huggingface.co/), provides APIs to quickly download and use thousands of pretrained models to perform tasks on text, images, and audio.\n",
    "\n",
    "Install the `transformers` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83ce3601-38ea-4e4a-9b3f-bca0867747ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/jupyter-subwaymatch/.local/lib/python3.10/site-packages (4.48.0)\n",
      "Requirement already satisfied: filelock in /home/jupyter-subwaymatch/.local/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/jupyter-subwaymatch/.local/lib/python3.10/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jupyter-subwaymatch/.local/lib/python3.10/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/tljh/user/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/tljh/user/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jupyter-subwaymatch/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/tljh/user/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/jupyter-subwaymatch/.local/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jupyter-subwaymatch/.local/lib/python3.10/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/tljh/user/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jupyter-subwaymatch/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/tljh/user/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/tljh/user/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/tljh/user/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/tljh/user/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66cd881-ae04-433b-a37a-9a6efe67bad0",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "\n",
    "Pipelines are objects that abstract complex code from the Hugging Face library into simple APIs for inference tasks.\n",
    "\n",
    "The `\"sentiment-analysis\"` pipeline uses the default model for sentiment analysis (`distilbert/distilbert-base-uncased-finetuned-sst-2-english`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5528104-0874-4679-82cf-b767661f03d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4860287-0be0-401a-9db2-3eb8498da6a4",
   "metadata": {},
   "source": [
    "### Run the sentiment classifier\n",
    "\n",
    "The `distilbert-base-uncased-finetuned-sst-2-english` model classifies an input text to 'POSITIVE' or 'NEGATIVE' labels, along with confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82f9b821-d836-4df2-bf35-802ade1b2ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"We are very happy to show you the ü§ó Transformers library.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3af402-ca7e-4bc6-aa07-6a1709beff68",
   "metadata": {},
   "source": [
    "üëÜ For the 'POSITIVE' label: The score of 0.9997795224189758 indicates a very high confidence (about 99.98%) that the input text expresses a positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2ede150-76f9-4196-a98f-ae0ce660ad46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.996752142906189}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"These thieves tried to steal my security deposit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e731835-264b-4bb7-b597-5056722ea1ad",
   "metadata": {},
   "source": [
    "üëÜ  For the 'NEGATIVE' label: The score of 0.996752142906189 indicates a very high confidence (about 99.68%) that the input text expresses a negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54744cd9-8d4c-4305-b01c-bcfdc1f2aabe",
   "metadata": {},
   "source": [
    "You can supply multiple inputs to the pipeline as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c893dc20-af5f-49a5-a075-a4a61b1dea0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998639822006226},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997650980949402}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_inputs = [\n",
    "    \"You're the best!\",\n",
    "    \"You're the worst!\"\n",
    "]\n",
    "\n",
    "classifier(my_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b5792-caf2-4265-8302-b104fffd7917",
   "metadata": {},
   "source": [
    "#### Sample 30 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5226e927-e0cd-4b77-bf80-64e7b6c17bb7",
   "metadata": {},
   "source": [
    "Although the `distilbert-base-uncased-finetuned-sst-2-english` model is pre-trained and distilled (40% smaller than the original BERT model), it will still be slow to be used for the entire dataset.\n",
    "\n",
    "For this demo, only sample 30 rows where \n",
    "\n",
    "1. review_text is not missing, and\n",
    "2. review_rating is less than or equal to 4 out of 5 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "585c67cb-91d7-4b8c-8ab4-fdd75123188f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>Office staff extremely rude. Have laundry mach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>NEVER LIVE HERE!! They don't charge a security...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>I lived here for a year and it was FAR too lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1</td>\n",
       "      <td>Avoid living here at all costs. The other revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>Very poor management.  They seem nice and trea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>They have maintenance come without any warning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1</td>\n",
       "      <td>This is one of the most pricey places to live ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1</td>\n",
       "      <td>Bribed students to write a review to be entere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3</td>\n",
       "      <td>Great place to live! But when it gets snowy it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2</td>\n",
       "      <td>** The reason there are so many positive revie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>Edited to respond to comments from management:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>Honestly 2.5 stars is more appropriate but I'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>DO NOT LIVE HERE. Spaces are smaller than what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>DO NOT LIVE HERE!!!!\\nManagement is horrible a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>This complex is a joke. They don‚Äôt answer your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>Extremely upset after finding out that ‚Äúthe co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>Management here is not that great. I understan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>My daughter rented at this horrible complex. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>Staff is deplorable. Maintenance let my dog ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>4</td>\n",
       "      <td>After a minor dispute on move out charges the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>The pipe burst this apartment upstairs office ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>DON'T LIVE HERE! They faked on the advertiseme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>This place is the absolute worse. They get mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1</td>\n",
       "      <td>Visited the Standard to take a tour a few days...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>I am extremely disappointed in the Standard. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the most horrible apartment complex I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>4</td>\n",
       "      <td>Clean space with cool atmosphere. Place can be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1</td>\n",
       "      <td>Over priced,  people around you are loud and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>I stayed in this terrible apartment a few year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>There is a big lack of communication around ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_rating                                        review_text\n",
       "60               1  Office staff extremely rude. Have laundry mach...\n",
       "5                1  NEVER LIVE HERE!! They don't charge a security...\n",
       "68               1  I lived here for a year and it was FAR too lon...\n",
       "193              1  Avoid living here at all costs. The other revi...\n",
       "49               1  Very poor management.  They seem nice and trea...\n",
       "65               1  They have maintenance come without any warning...\n",
       "194              1  This is one of the most pricey places to live ...\n",
       "212              1  Bribed students to write a review to be entere...\n",
       "88               3  Great place to live! But when it gets snowy it...\n",
       "207              2  ** The reason there are so many positive revie...\n",
       "62               1  Edited to respond to comments from management:...\n",
       "41               3  Honestly 2.5 stars is more appropriate but I'm...\n",
       "76               1  DO NOT LIVE HERE. Spaces are smaller than what...\n",
       "53               1  DO NOT LIVE HERE!!!!\\nManagement is horrible a...\n",
       "87               1  This complex is a joke. They don‚Äôt answer your...\n",
       "47               1  Extremely upset after finding out that ‚Äúthe co...\n",
       "54               1  Management here is not that great. I understan...\n",
       "35               1  My daughter rented at this horrible complex. P...\n",
       "31               1  Staff is deplorable. Maintenance let my dog ou...\n",
       "90               4  After a minor dispute on move out charges the ...\n",
       "93               1  The pipe burst this apartment upstairs office ...\n",
       "97               1  DON'T LIVE HERE! They faked on the advertiseme...\n",
       "26               1  This place is the absolute worse. They get mon...\n",
       "203              1  Visited the Standard to take a tour a few days...\n",
       "221              1  I am extremely disappointed in the Standard. H...\n",
       "63               1  This is the most horrible apartment complex I ...\n",
       "100              4  Clean space with cool atmosphere. Place can be...\n",
       "130              1  Over priced,  people around you are loud and r...\n",
       "17               1  I stayed in this terrible apartment a few year...\n",
       "196              1  There is a big lack of communication around ma..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df_r[df_r['review_text'].notna() & \n",
    "    (df_r['review_rating'] <= 4)].sample(30)\n",
    "\n",
    "df_sample[['review_rating', 'review_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d978e6b3-80ca-4a03-8ca0-b5bb9bc5c955",
   "metadata": {},
   "source": [
    "#### Run the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c052d-a845-4799-80e6-582ba533b077",
   "metadata": {},
   "source": [
    "**`truncation=True`** enables truncation of input sequences that exceed the maximum length accepted by the model. This prevents errors that would occur if the input text is too long for the model to process.\n",
    "\n",
    "**`max_length=512`** sets the maximum number of tokens that each input sequence can have after tokenization. If an input sequence is longer than this, it will be truncated to fit within this limit. The value 512 is commonly used, as it's the maximum sequence length for many BERT-based models.\n",
    "\n",
    "**`padding=True`** enables padding for input sequences that are shorter than the maximum length15. This ensures that all input sequences in a batch have the same length, which is necessary for efficient processing by the model. Shorter sequences are padded with a special padding token to reach the specified maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d0feca4-6660-408c-aea3-c5f157907d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.999226450920105},\n",
       " {'label': 'NEGATIVE', 'score': 0.9996181726455688},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997121691703796},\n",
       " {'label': 'NEGATIVE', 'score': 0.9996076226234436},\n",
       " {'label': 'NEGATIVE', 'score': 0.9990652203559875},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995266199111938},\n",
       " {'label': 'NEGATIVE', 'score': 0.9992621541023254},\n",
       " {'label': 'NEGATIVE', 'score': 0.9993144273757935},\n",
       " {'label': 'POSITIVE', 'score': 0.9229395985603333},\n",
       " {'label': 'NEGATIVE', 'score': 0.9996793270111084},\n",
       " {'label': 'NEGATIVE', 'score': 0.9989628791809082},\n",
       " {'label': 'NEGATIVE', 'score': 0.9937936067581177},\n",
       " {'label': 'NEGATIVE', 'score': 0.998755693435669},\n",
       " {'label': 'NEGATIVE', 'score': 0.9998036026954651},\n",
       " {'label': 'NEGATIVE', 'score': 0.9996813535690308},\n",
       " {'label': 'NEGATIVE', 'score': 0.9992544054985046},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995424747467041},\n",
       " {'label': 'NEGATIVE', 'score': 0.9993053674697876},\n",
       " {'label': 'NEGATIVE', 'score': 0.9993048906326294},\n",
       " {'label': 'POSITIVE', 'score': 0.9937560558319092},\n",
       " {'label': 'NEGATIVE', 'score': 0.999752938747406},\n",
       " {'label': 'NEGATIVE', 'score': 0.9948915243148804},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997307658195496},\n",
       " {'label': 'NEGATIVE', 'score': 0.9974057078361511},\n",
       " {'label': 'NEGATIVE', 'score': 0.9996538162231445},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995594620704651},\n",
       " {'label': 'POSITIVE', 'score': 0.8697509765625},\n",
       " {'label': 'NEGATIVE', 'score': 0.9998201727867126},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997301697731018},\n",
       " {'label': 'NEGATIVE', 'score': 0.9996767044067383}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_result = classifier(\n",
    "    df_sample['review_text'].tolist(),\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "classified_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb6c98-54d9-448a-b3a7-f3ac4b991d6e",
   "metadata": {},
   "source": [
    "Check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20f56396-af18-428d-be06-dd0980480704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Office staff extremely rude. Have laundry mach...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NEVER LIVE HERE!! They don't charge a security...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>I lived here for a year and it was FAR too lon...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Avoid living here at all costs. The other revi...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Very poor management.  They seem nice and trea...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>They have maintenance come without any warning...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>This is one of the most pricey places to live ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Bribed students to write a review to be entere...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Great place to live! But when it gets snowy it...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.922940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>** The reason there are so many positive revie...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Edited to respond to comments from management:...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Honestly 2.5 stars is more appropriate but I'm...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.993794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>DO NOT LIVE HERE. Spaces are smaller than what...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>DO NOT LIVE HERE!!!!\\nManagement is horrible a...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>This complex is a joke. They don‚Äôt answer your...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Extremely upset after finding out that ‚Äúthe co...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Management here is not that great. I understan...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>My daughter rented at this horrible complex. P...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Staff is deplorable. Maintenance let my dog ou...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>After a minor dispute on move out charges the ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.993756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>The pipe burst this apartment upstairs office ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>DON'T LIVE HERE! They faked on the advertiseme...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.994892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>This place is the absolute worse. They get mon...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Visited the Standard to take a tour a few days...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.997406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>I am extremely disappointed in the Standard. H...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>This is the most horrible apartment complex I ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Clean space with cool atmosphere. Place can be...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.869751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Over priced,  people around you are loud and r...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I stayed in this terrible apartment a few year...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>There is a big lack of communication around ma...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review_text sentiment     score\n",
       "60   Office staff extremely rude. Have laundry mach...  NEGATIVE  0.999226\n",
       "5    NEVER LIVE HERE!! They don't charge a security...  NEGATIVE  0.999618\n",
       "68   I lived here for a year and it was FAR too lon...  NEGATIVE  0.999712\n",
       "193  Avoid living here at all costs. The other revi...  NEGATIVE  0.999608\n",
       "49   Very poor management.  They seem nice and trea...  NEGATIVE  0.999065\n",
       "65   They have maintenance come without any warning...  NEGATIVE  0.999527\n",
       "194  This is one of the most pricey places to live ...  NEGATIVE  0.999262\n",
       "212  Bribed students to write a review to be entere...  NEGATIVE  0.999314\n",
       "88   Great place to live! But when it gets snowy it...  POSITIVE  0.922940\n",
       "207  ** The reason there are so many positive revie...  NEGATIVE  0.999679\n",
       "62   Edited to respond to comments from management:...  NEGATIVE  0.998963\n",
       "41   Honestly 2.5 stars is more appropriate but I'm...  NEGATIVE  0.993794\n",
       "76   DO NOT LIVE HERE. Spaces are smaller than what...  NEGATIVE  0.998756\n",
       "53   DO NOT LIVE HERE!!!!\\nManagement is horrible a...  NEGATIVE  0.999804\n",
       "87   This complex is a joke. They don‚Äôt answer your...  NEGATIVE  0.999681\n",
       "47   Extremely upset after finding out that ‚Äúthe co...  NEGATIVE  0.999254\n",
       "54   Management here is not that great. I understan...  NEGATIVE  0.999542\n",
       "35   My daughter rented at this horrible complex. P...  NEGATIVE  0.999305\n",
       "31   Staff is deplorable. Maintenance let my dog ou...  NEGATIVE  0.999305\n",
       "90   After a minor dispute on move out charges the ...  POSITIVE  0.993756\n",
       "93   The pipe burst this apartment upstairs office ...  NEGATIVE  0.999753\n",
       "97   DON'T LIVE HERE! They faked on the advertiseme...  NEGATIVE  0.994892\n",
       "26   This place is the absolute worse. They get mon...  NEGATIVE  0.999731\n",
       "203  Visited the Standard to take a tour a few days...  NEGATIVE  0.997406\n",
       "221  I am extremely disappointed in the Standard. H...  NEGATIVE  0.999654\n",
       "63   This is the most horrible apartment complex I ...  NEGATIVE  0.999559\n",
       "100  Clean space with cool atmosphere. Place can be...  POSITIVE  0.869751\n",
       "130  Over priced,  people around you are loud and r...  NEGATIVE  0.999820\n",
       "17   I stayed in this terrible apartment a few year...  NEGATIVE  0.999730\n",
       "196  There is a big lack of communication around ma...  NEGATIVE  0.999677"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['sentiment'] = list(map(lambda f: f['label'], classified_result))\n",
    "df_sample['score'] = list(map(lambda f: f['score'], classified_result))\n",
    "\n",
    "df_sample[['review_text', 'sentiment', 'score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688df354-138c-4acf-b97a-81aaaf3741ae",
   "metadata": {},
   "source": [
    "#### Alternatively, use a for loop to display progress\n",
    "\n",
    "Passing a long list of text can be time-consuming. If you prefer tracking progress while the pipeline is running, use a for loop to run the classifier on each row. Print progress in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "914e53c4-7b31-414f-b9cb-4b82967d2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns to store classified result\n",
    "df_sample['sentiment'] = np.nan\n",
    "df_sample['score'] = np.nan\n",
    "\n",
    "# set the sentiment column to a string dtype\n",
    "df_sample['sentiment'] = df_sample['sentiment'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b943fe4-e188-4215-a917-b4d21da7b6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/30 (3.33%) 2/30 (6.67%) 3/30 (10.0%) 4/30 (13.33%) 5/30 (16.67%) 6/30 (20.0%) 7/30 (23.33%) 8/30 (26.67%) 9/30 (30.0%) 10/30 (33.33%) \n",
      "11/30 (36.67%) 12/30 (40.0%) 13/30 (43.33%) 14/30 (46.67%) 15/30 (50.0%) 16/30 (53.33%) 17/30 (56.67%) 18/30 (60.0%) 19/30 (63.33%) 20/30 (66.67%) \n",
      "21/30 (70.0%) 22/30 (73.33%) 23/30 (76.67%) 24/30 (80.0%) 25/30 (83.33%) 26/30 (86.67%) 27/30 (90.0%) 28/30 (93.33%) 29/30 (96.67%) 30/30 (100.0%) \n",
      "====================\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "num_rows = df_sample.shape[0]\n",
    "\n",
    "for i in range(num_rows):\n",
    "  # store review text to a variable\n",
    "  review_text = df_sample['review_text'].iloc[i]\n",
    "\n",
    "  if pd.notna(review_text):\n",
    "    result = classifier(\n",
    "        review_text,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    df_sample.iloc[i, df_sample.columns.get_loc('sentiment')] = result[0]['label']\n",
    "    df_sample.iloc[i, df_sample.columns.get_loc('score')] = result[0]['score']\n",
    "\n",
    "  # display progress\n",
    "  progress_percentage = round((i + 1) / num_rows * 100, 2)\n",
    "  print(f'{i + 1}/{num_rows} ({progress_percentage}%)', end=' ')\n",
    "\n",
    "  if (i + 1) % 10 == 0:\n",
    "    print('')\n",
    "\n",
    "print('====================')\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa3e9d1-a10e-453a-85d3-e6280abaf91f",
   "metadata": {},
   "source": [
    "## ‚ú® Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5844a22-8c66-4582-a7d3-9999c4125895",
   "metadata": {},
   "source": [
    "Rule-based models like [VADER](https://github.com/cjhutto/vaderSentiment) struggle with nuanced language comprehension and context-dependent sentiments. BERT-based sentiment analysis models generally outperform rule-based models like VADER in terms of accuracy and nuanced understanding of context. BERT's bidirectional training allows it to grasp context from both directions, making it more effective in understanding complex sentiments.\n",
    "\n",
    "ModernBERT was [recently introduced](https://huggingface.co/blog/modernbert), which is a *slot-in* replacement for any BERT-like models. ModernBERT is an improvment over its younger siblings across both **speed** and **accuracy**. Hugging Face expects to see ModernBERT become the new standard for applications where encoder-only models are now deployed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
